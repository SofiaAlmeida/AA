%%%
% Plantilla de Memoria
% Modificación de una plantilla de Latex de Nicolas Diaz para adaptarla 
% al castellano y a las necesidades de escribir informática y matemáticas.
%
% Editada por: Mario Román
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Thin Sectioned Essay
% LaTeX Template
% Version 1.0 (3/8/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original Author:
% Nicolas Diaz (nsdiaz@uc.cl) with extensive modifications by:
% Vel (vel@latextemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PAQUETES Y CONFIGURACIÓN DEL DOCUMENTO
%----------------------------------------------------------------------------------------

%%% Configuración del papel.
% microtype: Tipografía.
% mathpazo: Usa la fuente Palatino.
\documentclass[a4paper, 20pt]{article}
\usepackage[a4paper,margin=1in]{geometry}
\usepackage[protrusion=true,expansion=true]{microtype}
\usepackage{mathpazo}

% Indentación de párrafos para Palatino
\setlength{\parindent}{0pt}
  \parskip=8pt
\linespread{1.05} % Change line spacing here, Palatino benefits from a slight increase by default


%%% Castellano.
% noquoting: Permite uso de comillas no españolas.
% lcroman: Permite la enumeración con numerales romanos en minúscula.
% fontenc: Usa la fuente completa para que pueda copiarse correctamente del pdf.
\usepackage[spanish,es-noquoting,es-lcroman,es-tabla,,es-nodecimaldot]{babel}
\usepackage[utf8]{inputenc}
\usepackage{fontenc}
\selectlanguage{spanish}


%%% Gráficos
\usepackage{graphicx} % Required for including pictures
\usepackage{wrapfig} % Allows in-line images
\usepackage[usenames,dvipsnames]{color} % Coloring code
\usepackage{subcaption}
\graphicspath{{./fig/}}


%%% Matemáticas
\usepackage{amsmath}
\usepackage{physics} % para las derivadas parciales
\usepackage[Symbol]{upgreek} %pi

%%% Pseudocódigo
\usepackage{algorithmicx}
\usepackage[ruled]{algorithm}
\usepackage{algpseudocode}

\newcommand{\alg}{\texttt{algorithmicx}}
\newcommand{\old}{\texttt{algorithmic}}
\newcommand{\euk}{Euclid}
\newcommand\ASTART{\bigskip\noindent\begin{minipage}[b]{0.5\linewidth}}
\newcommand\ACONTINUE{\end{minipage}\begin{minipage}[b]{0.5\linewidth}}
\newcommand\AENDSKIP{\end{minipage}\bigskip}
\newcommand\AEND{\end{minipage}}

%%% Código
\usepackage{listings}

%%% Tablas
\usepackage{tabularx}
\usepackage{float}
\usepackage{adjustbox}
\usepackage{booktabs}

% Enlaces y colores
\usepackage{hyperref}
\usepackage[dvipsnames]{xcolor}
\definecolor{webgreen}{rgb}{0,0.5,0}
\hypersetup{
  colorlinks=true,
  citecolor=RoyalBlue,
  urlcolor=RoyalBlue,
  linkcolor=RoyalBlue
}

%%% Bibliografía
\usepackage[backend=biber]{biblatex}
\DefineBibliographyStrings{spanish}{
  urlseen = {Último acceso}
}
\addbibresource{IN-P2.bib}

%----------------------------------------------------------------------------------------
%	TÍTULO
%----------------------------------------------------------------------------------------
% Configuraciones para el título.
% El título no debe editarse aquí.
\renewcommand{\maketitle}{
  \begin{flushright} % Right align
  
  {\LARGE\@title} % Increase the font size of the title
  
  \vspace{50pt} % Some vertical space between the title and author name
  
  {\large\@author} % Author name
  \\\@date % Date
  \vspace{40pt} % Some vertical space between the author block and abstract
  \end{flushright}
}

%% Título
\title{\textbf{Título}\\ % Title
Subtítulo} % Subtitle

\author{\textsc{Autor1,\\Autor2} % Author
\\{\textit{Universidad de Granada}}} % Institution

\date{\today} % Date

%-----------------------------------------------------------------------------------------
%	DOCUMENTO
%-----------------------------------------------------------------------------------------

\begin{document}

%-----------------------------------------------------------------------------------------
%	TITLE PAGE
%-----------------------------------------------------------------------------------------

\begin{titlepage} % Suppresses displaying the page number on the title page and the subsequent page counts as page 1
	
	\raggedleft % Right align the title page
	
	\rule{1pt}{\textheight} % Vertical line
	\hspace{0.05\textwidth} % Whitespace between the vertical line and title page text
	\parbox[b]{0.8\textwidth}{ % Paragraph box for holding the title page text, adjust the width to move the title page left or right on the page
		
		{\Huge\bfseries Trabajo 1:\\[0.5\baselineskip] Programación\\[2\baselineskip]} % Title
		{\large\textit{Curso 2019/2020}\\[0.5\baselineskip]Aprendizaje Automático\\[1\baselineskip] }% Subtitle or further description
		{\Large\textsc{Sofía Almeida Bruno}\\[0.5\baselineskip]sofialmeida@correo.ugr.es} % Author name, lower case for consistent small caps
		
		\vspace{0.4\textheight} % Whitespace between the title block and the publisher
		
		{\noindent \\[0.5\baselineskip] }\\[\baselineskip] % Publisher and logo
	}

\end{titlepage}

%% Resumen (Descomentar para usarlo)
%\renewcommand{\abstractname}{Resumen} % Uncomment to change the name of the abstract to something else
%\begin{abstract}
% Resumen aquí
%\end{abstract}

%% Palabras clave
%\hspace*{3,6mm}\textit{Keywords:} lorem , ipsum , dolor , sit amet , lectus % Keywords
%\vspace{30pt} % Some vertical space between the abstract and first section


%% Índice
{\parskip=2pt
  \tableofcontents
}
\pagebreak

%%% Inicio del documento
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%       EJERCICIO 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\large
\section{Ejercicio sobre la búsqueda iterativa de óptimos - Gradiente Descendente}
\subsection{Implementar el algoritmo de gradiente descendente}
Este algoritmo se encuentra implementado en el archivo \texttt{ej1.py}. El algoritmo desarrollado se encuentra en la función \texttt{gd} y toma como parámetros:

\begin{itemize}
\item \texttt{w}: valor inicial del vector de pesos.
\item \texttt{lr}: \textit{learning rate}, tasa de aprendizaje.
\item \texttt{grad\_fun}: gradiente de la función a minimizar.
\item \texttt{fun}: función a minimizar.
\item \texttt{epsilon}: umbral para determinar el final del bucle, si la función para el vector \texttt{w} es inferior a este valor, habremos terminado.
\item \texttt{max\_iters}: número máximo de iteraciones.
\end{itemize}

\subsection{Considerar la función $E(u,v) = (ue^v - 2ve^{-u})^2$}
Pintamos la función correspondiente para hacernos una idea de su forma y en qué punto o puntos alcanza un mínimo. La podemos ver en la Figura \ref{fig:E}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{e1}
    \caption{Función $E$.}
    \label{fig:E}
\end{figure}

Notamos que se minimiza en varios puntos, aparentemente cuando la $u$ y $v$ se acercan al 0.

\textbf{Usar gradiente descendente para encontrar un mínimo de esta función, comenzando desde el punto $(u, v) = (1, 1)$ y usando una tasa de aprendizaje $\eta = 0,1$.\\
a) Calcular analíticamente y mostrar la expresión del gradiente de la función $E(u, v)$}

Para usar el gradiente descendente para encontrar un mínimo de esta función necesitaremos el gradiente de  la misma.
\begin{align*}
\pdv{E}{u}(u,v) &= 2(ue^v - 2ve^{-u})(e^v+2ve^{-u}),\\
\pdv{E}{v}(u,v) &= 2(ue^v - 2ve^{-u})(ue^v-2e^{-u}),\\
\grad{E}(u,v) &= \left(\pdv{E}{u}(u,v), \pdv{E}{v}(u,v)\right)^T\\
	      &= 2(ue^v - 2ve^{-u})\left((e^v+2ve^{-u}),\ (ue^v-2e^{-u})\right)^T.
\end{align*}

\textbf{b) ¿Cuántas iteraciones tarda el algoritmo en obtener por primera vez un valor de $E(u, v)$ inferior a $10^{-14}$? (Usar flotantes de 64 bits)}

Partiendo de un valor inicial de $E(1,1) =  3.9303972318771003$, el algoritmo necesita 10 iteraciones para obtener un valor inferior a $10^{-14}$, $1.2086833944220747e-15$.

\textbf{c) ¿En qué coordenadas $(u, v)$ se alcanzó por primera vez un valor igual o menor a $10^{-14}$ en el apartado anterior.}

Este valor se obtuvo en las coordenadas: $(0.04473629039778207,  0.023958714099141746)$.

\subsection{Considerar ahora la función $f(x, y) = (x - 2)^2 + 2(y + 2)^2 + 2 \sin{(2 \pi x)} \sin(2\pi y)$}

Comenzamos generando el gráfico de la función para ver qué forma tiene. En la Figura \ref{fig:f1} vemos que la función tiene numerosos mínimos locales, lo que sospechamos que generará dificultades a la hora de encontrar el mínimo global, por poder quedar estancado el algoritmo en algún mínimo local.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{f1}
    \caption{Función $f$.}
    \label{fig:f1}
\end{figure}

\textbf{a) Usar gradiente descendente para minimizar esta función. Usar como punto inicial $(x_0 = 1, y_0 = -1)$, tasa de aprendizaje $\eta = 0,01$ y un máximo de 50 iteraciones.
Generar un gráfico de cómo desciende el valor de la función con las iteraciones. Repetir
el experimento pero usando $\eta = 0,1$, comentar las diferencias y su dependencia de $\eta$.}

Para usar el gradiente descendente necesitamos calcular el gradiente de la función que en este caso es:
\begin{align*}
\pdv{f}{x}(x,y) &= 2(x-2) + 4\pi \sin(2\pi y) \cos(2\pi x),\\
\pdv{f}{y}(x,y) &= 4(y+2)+4\pi \sin(2\pi x) \cos(2\pi y),\\
\grad{f}(x,y) &= \left(\pdv{f}{x}(x,y), \pdv{E}{y}(x,y)\right)^T\\
	      &= 2\left((x-2) + 2\pi \sin(2\pi y) \cos(2\pi x),\ 2(y+2)+2pi \sin(2\pi x) \cos(2\pi y)\right)^T.
\end{align*}

Tomaremos como parámetro, además de los impuestos para este experimento, \texttt{max\_iters} = 50.

\begin{figure}[H]
\centering
\begin{subfigure}{0.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{1lr0_01}
  \caption{$\eta = 0.01$.}
  \label{fig:0.01}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{1lr0_1}
  \caption{$\eta = 0.1$.}
  \label{fig:0.1}
\end{subfigure}
\caption{Valor de $f(x,y)$.}
\label{fig:test}
\end{figure}

En la Figura \ref{fig:0.01} vemos un gráfico de cómo desciende el valor de la función $f$ con las iteraciones cuando la tasa de aprendizaje es $0.01$, en la Figura \ref{fig:0.1} se ha generado el mismo gráfico para la tasa de aprendizaje $0.1$.

En un primer vistazo notamos que en la Figura \ref{fig:0.1} el valor de la función no es cada vez menor, su monotonía va cambiando. En el caso $\eta = 0.01$ la gráfica sí que es descendente, de hecho se estabiliza a partir de la quinta iteración. ¿A qué se debe esta diferencia?

La tasa de aprendizaje es un factor multiplicativo en la actualización del vector de pesos $w$, cuando vale 0.01 es pequeño y nos vamos desplazando en la dirección del gradiente poco a poco, hasta alcanzar un mínimo. Sin embargo, en el caso 0.1, ligeramente mayor, nos movemos dando pasos mayores en la dirección del gradiente, esto provoca que nos vayamos encontrando con diferentes mínimos y al aproximarnos a ellos, terminar alejándonos de uno para caer en otro. 

\textbf{b) Obtener el valor mínimo y los valores de las variables $(x, y)$ en donde se alcanzan cuando el punto de inicio se fija en: $(2,1, -2,1), (3, -3),(1,5, 1,5),(1, -1)$. Generar una
tabla con los valores obtenidos.}

Para esta experimentación se ha utilizado \texttt{lr} = 0.01 y \texttt{max\_iters} = 50 (se comprueba empíricamente que es un número de iteraciones suficientes para alcanzar el mínimo).

\begin{table}[H]
\centering
\caption{Valor mínimo de $f$ y dónde se alcanza según el punto inicial.}
\label{tab:f}
\begin{tabular}{llll}
\toprule
$(x_0, y_0)$ & $x$ & $y$ & $f(x,y)$\\ \midrule
$(2.1, -2.1)$ & 2.2438049693647883 & -2.237925821486178 & -1.8200785415471563\\
$(3.0,-3.0)$ & 2.7309356482481055 & -2.7132791261667037 & -0.38124949743809955\\
$(1.5, 1.5)$ & 1.7779244744891156 & 1.032056872669696 & 18.042078009957635\\
$(1.0, -1.0)$ & 1.7566613758319838 & -0.8117887547719083 & 1.0333658794298513\\
\bottomrule
\end{tabular}
\end{table}

Observamos en la Tabla \ref{tab:f} que los valores mínimos alcanzados difieren según el punto inicial tomado. Si observamos la Figura \ref{fig:f1+pts} notamos que el punto $(2.1, -2.1)$ tiene un valor de la función $f$ menor que los correspondientes al resto de valores iniciales, es por esto que al aplicar el algoritmo alcanza el mínimo global. Al ser el resto de puntos mayores, alcanzan mínimos  locales y se quedan estancados en ellos. El caso más destacable es el del punto $(1.5, 1.5)$, el valor mínimo obtenido al partir de este punto difiere enormemente de los obtenidos con el resto de puntos, esto se debe, como ya se ha comentado, a que se parte de un valor más alto de la función $f$ que queda atrapado en un mínimo local.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{f1+pts}
    \caption{Función $f$ y puntos iniciales.}
    \label{fig:f1+pts}
\end{figure}


\subsection{¿Cuál sería su conclusión sobre la verdadera dificultad de encontrar el mínimo
global de una función arbitraria?}

Para encontrar un mínimo global de una función arbitraria creo que la dificultad no estriba en el algoritmo en sí, cuya posible dificultad es el cálculo de las derivadas parciales de las funciones, sino la determinación de los parámetros a utilizar.

En los ejercicios anteriores hemos probado epíricamente cómo, lo que a priori parecían ligeras variaciones en los parámetros, provocaron grandes diferencias en los resultados. Por un lado,  una tasa de aprendizaje mayor que la apropiada podría implicar que en cada iteración los valores de $w$ fueran oscilando sobre la función sin llegar a un óptimo. Mientras que, si este fuera demasiado pequeño, el algoritmo podría necesitar muchas iteraciones para converger. El punto inicial es también determinante en este sentido, si la función tiene varios mínimos locales y partimos cerca de uno que no sea el mínimo absoluto de la función, el algoritmo podría devolvernos como valor mínimo alguno de los mínimos locales.

Por tanto, la dificultad de este algoritmo consiste en encontrar la combinación de parámetros, desconocida, que nos permita alcanzar el mínimo global de la función, sin caer en óptimos locales ni quedarse oscilando.
\newpage
\section{Ejercicio sobre Regresión Lineal}
\textbf{Este ejercicio ajusta modelos de regresión a vectores de características extraidos de imágenes de digitos manuscritos. En particular se extraen dos característcas concretas: el valor medio del nivel de gris y simetría del número respecto de su eje vertical. Solo se seleccionarán para este ejercicio las imágenes de los números 1 y 5.}

\subsection{Estimar un modelo de regresión lineal a partir de los datos proporcionados de dichos números (Intensidad promedio, Simetría) usando tanto el algoritmo de la pseudoinversa como Gradiente descendente estocástico (SGD).}
\textbf{Las etiquetas serán \{-1, 1\}, una para cada vector de cada uno de los números. Pintar las soluciones obtenidas junto con los datos usados en el ajuste. Valorar la bondad del resultado usando $E_{in}$ y $E_{out}$ (para $E_{out}$ calcular las predicciones usando los datos del fichero de test). (usar \texttt{Regress\_Lin(datos, label)} como llamada para la función (opcional)).}

El código implementado en este apartado se encuentra en el archivo \texttt{ej2.py}. En él se escribieron las funciones correspondientes al algoritmo del gradiente descendente estocástico (SGD) en la función \texttt{sgd} y el de la pseudoinversa, en la función \texttt{pseudoinverse}. Ambos toman como parámetros una matriz, \texttt{x}, que contendrá las características de los ejemplos dados (intensidad promedio y simetría, además de un 1 ya que al buscamos un hiperplano con término independiente) y un vector, \texttt{y}, que contiene la clase asociada a dichos elementos. La función \texttt{sgd} además de estos toma como parámetros: \texttt{lr}, la tasa de aprendizaje; \texttt{max\_iters}, número máximo de iteraciones; y \texttt{tam\_minibatch}, el tamaño de cada \textit{minibatch}.

Para la ejecución se han utilizado los conjuntos \texttt{x}, \texttt{y} proporcionados, \texttt{lr} = 0.1, \texttt{max\_iters} = 75 y \texttt{tam\_minibatch} = 75, pues empíricamente se ha comprobado que eran los valores que mejores resultados daban.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{results2}
    \caption{Resultado del ajuste con ambos algoritmos.}
    \label{fig:2c}
\end{figure}

En la Figura \ref{fig:2c} observamos las rectas resultantes del ajuste junto a los datos con los que se realizó el mismo (coloreados según su clase). Destaca el hecho de que las rectas separan las clases bastante bien, aunque no son iguales. La clase -1 (número 1) se encuentra bastante concentrada, con puntos excepcionales con simetría menor que -2.5, las rectas determinan bien las clases de estos puntos si obviamos estas excepciones. La clase 1 (número 5) está un poco más dispersa, las diferencias en los resultados vienen provocados por la correcta clasificación de los puntos que se alejan más del ``centroide'' de la clase. Para saber realmente qué ajuste fue mejor debemos comparar el error obtenido, no solo con los datos de entrenamiento sino también con los de prueba.

\begin{table}[H]
\large
\centering
\caption{Errores obtenidos con ambos algoritmos.}
\label{tab:21}
\begin{tabular}{lll}
\toprule
 & $E_{in}$ & $E_{out}$ \\ \midrule
SGD & 0.082238870568555 & 0.13967094647032663 \\
Pseudoinversa & 0.07918658628900395 & 0.13095383720052578 \\
\bottomrule
\end{tabular}
\end{table}

En la Tabla \ref{tab:21} podemos comparar los errores obtenidos con ambos algoritmos. Como se intuye al observar las rectas resultantes, los errores son muy pequeños y ambos del mismo orden. En ambos casos, como es natural, los errores cometidos con el conjunto de entrenamiento son menores que con el conjunto de \textit{test}. Esto es natural porque el ajuste se ha realizado utilizando los datos del conjunto de entrenamiento, los datos de prueba no eran conocidos y solo se usaron a posteriori para medir el error. El algoritmo de la pseudoinversa consigue un ligero mejor resultado (una diferencia tan pequeña debe ser causada por pocos puntos), pero como el gradiente descendente estocástico tiene más parámetros que ajustar, no podemos asegurar que este método sea mejor en general.

\subsection{En este apartado exploramos cómo se transforman los errores $E_{in}$ y $E_{out}$ cuando aumentamos la complejidad del modelo lineal usado}
\textbf{Ahora hacemos uso de la función \texttt{simula\_unif(N, 2, size)} que nos devuelve $N$ coordenadas 2D de puntos uniformemente muestreados dentro del cuadrado definido por [-size, size] $\times$ [-size, size]}

\textbf{a) Generar una muestra de entrenamiento de N = 1000 puntos en el cuadrado $\mathcal{X} = [-1, 1] \times [-1, 1]$. Pintar el mapa de puntos 2D. (ver función de ayuda)}

Se implementa la función \texttt{simula\_unif} para generar la muestra, llamándola con los parámetros del enunciado se obtiene la muestra que podemos ver en la Figura \ref{fig:22a}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{muestra2d}
    \caption{Muestra formada por 1000 elementos uniformemente tomados en el cuadrado $[-1,1]\times[-1,1]$.}
    \label{fig:22a}
\end{figure}

\textbf{b) Consideremos la función $f(x_1, x_2) = sign((x_1 - 0,2)^2 + x_2^2 - 0,6)$ que usaremos para asignar una etiqueta a cada punto de la muestra anterior. Introducimos ruido sobre las etiquetas cambiando aleatoriamente el signo de un 10\% de las mismas. Pintar el mapa de etiquetas obtenido.}

Para obtener las clases de los puntos creados anteriormente se implementó la función \texttt{classes} que recibe como parámetro una matriz \texttt{x} de tamaño $N\times 2$ y calcula la función $f$ para cada una de las muestras, a continuación introduce un error sobre el 10\% de las clases. En la Figura \ref{fig:22b} se puede observar las clases, diferenciadas por el color, que toman los puntos de la muestra. Notamos que las clases no son separables mediante una recta, lo que sospechamos que nos dará problemas al realizar la regresión.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{clases2d}
    \caption{Muestra formada por 1000 elementos uniformemente tomados en el cuadrado $[-1,1]\times[-1,1]$, con su clase correspondiente.}
    \label{fig:22b}
\end{figure}

\textbf{c) Usando como vector de características $(1, x_1 , x_2)$ ajustar un modelo de regresión lineal al conjunto de datos generado y estimar los pesos w. Estimar el error de ajuste $E_{in}$ usando Gradiente Descendente Estocástico (SGD).}

Utilizando las funciones ya definidas para el ejercicio anterior se ajusta un modelo mediante gradiente descendente estocástico (se toman los mismos parámetros), el código correspondiente se recoge en la función \texttt{experiment} que utiliza \texttt{get\_set} para obtener el conjunto. El error $E_{in}$ obtenido es de 0.9203296958016401, bastante más grande que en el caso anterior, también se ha creado un conjunto de prueba para calcular el $E_{out}$ que es de 0.9373964722120457. No es de extrañar que hayamos obtenido un error mucho mayor que el caso anterior, pues los datos no se pueden separar en 2 clases mediante una recta. En la Figura \ref{fig:22c} se encuentra pintada la recta obtenida con los datos utilizados para ajustarlos. Observamos que la recta no logra dividir a las clases, hará falta realizar otro tipo de aproximación al problema.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{results22}
    \caption{Muestra formada por 1000 elementos uniformemente tomados en el cuadrado $[-1,1]\times[-1,1]$, con su clase correspondiente y la recta ajustada mediante SGD que las intenta separar.}
    \label{fig:22c}
\end{figure}

\textbf{d) Ejecutar todo el experimento definido por (a)-(c) 1000 veces (generamos 1000 muestras diferentes) y calcular el valor medio de los errores $E_{in}$ de las 1000 muestras, generar 1000 puntos nuevos por cada iteración y calcular con ellos el valor de $E_{out}$ en dicha iteración. Calcular el valor medio de $E_{out}$ en todas las iteraciones.\\ 
e) Valore que tan bueno considera que es el ajuste con este modelo lineal a la vista de los valores medios obtenidos de $E_in$ y $E_out$}

Tras repetir el experimento 1000 veces se obtienen los siguientes errores:\[
E_{in} = 0.9278055100760753,
E_{out} = 0.9327054029399249.\]

Como ya se comentó, una recta no se puede separar bien a estos datos por cómo están distribuidas las clases. No importa si repetimos el experimento 1, 5 o 1000 veces, los errores obtenidos seguirán siendo bastante grandes. Hemos asegurado que no fue una mala ejecución del SGD (como tiene cierta aleatoriedad podría dar resultados diferentes en distintas ejecuciones) en todas las ejecuciones del mismo se obtienen malos ajustes. Por ello, concluimos que este modelo lineal no es adecuado para ajustar esta muestra.

\textbf{Repetir el mismo experimento anterior pero usando características no lineales. Ahora usaremos el siguiente vector de características: $\Phi_2 (x) = (1, x_1 , x_2 , x_1 x_2 , x^2_1, x^ 2_2)$. Ajustar el nuevo modelo de regresión lineal y calcular el nuevo vector de pesos $\hat{w}$. Calcular los errores promedio de $E_{in}$ y $E_out$.}

Para este experimento se ha creado la función \texttt{experiment\_nolineal} que no es más que una adaptación de la función \texttt{experiment} al caso no lineal que queremos tratar. Repetimos el experimento 1000 veces y obtenemos los siguientes errores medios:\[

\]




\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%       REFERENCIAS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\printbibliography
\end{document}
