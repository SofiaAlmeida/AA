{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño:  (1994, 128)\n",
      "Tamaño training:  (1495, 127) (1495,)\n",
      "Tamaño test:  (499, 127) (499,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "  Sofía Almeida Bruno\n",
    "  http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime \"\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "#plt.style.use('seaborn')\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "# Ajuste de parámetros\n",
    "def adjust_params(X, y, model, params):\n",
    "    print(\"------ Grid Search...\")\n",
    "    grid = GridSearchCV(model, params, cv=5, n_jobs=2, verbose=1, scoring='neg_mean_squared_error')\n",
    "    grid.fit(X, y)\n",
    "    print(\"Mejores parámetros:\")\n",
    "    print(grid.best_params_)\n",
    "    print(\"Error CV\")\n",
    "    print(-grid.best_score_)\n",
    "    return grid.best_estimator_\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "# Leemos los nombres de los atributos\n",
    "attributes = np.genfromtxt('./datos/communities.names', dtype = \"|U50\", skip_header = 75, max_rows = 128, delimiter = \" \")[:,1]\n",
    "\n",
    "# Leemos el conjunto de datos\n",
    "df = pd.read_csv('./datos/communities.data', sep=\",\", na_values ='?', names = attributes)\n",
    "df.name = 'Communities and Crimes'\n",
    "\n",
    "print(\"Tamaño: \", df.shape)\n",
    "\n",
    "# Dividimos en training y test\n",
    "X =  df.drop(labels = ['ViolentCrimesPerPop'], axis = 1)\n",
    "y = df['ViolentCrimesPerPop']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123456)\n",
    "\n",
    "print(\"Tamaño training: \", X_train.shape, y_train.shape)\n",
    "print(\"Tamaño test: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño train tras drop (5):  (1495, 122)\n",
      "Tamaño train tras drop (variables con mv) (1495, 100)\n",
      "Tras poli (1495, 5151)\n",
      "Tras var (1495, 150)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed: 10.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1495, 88)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-228cc87a8c92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# Preprocesado----------------------------------------------------------\n",
    "\n",
    "# Eliminamos las variables no predictivas\n",
    "to_drop = np.array(['state', 'county', 'community', 'communityname', 'fold'])\n",
    "X_train = X_train.drop(labels = to_drop, axis=1)\n",
    "print(\"Tamaño train tras drop (5): \", X_train.shape)\n",
    "\n",
    "mv_sum = X_train.isnull().sum()\n",
    "mv = mv_sum * 100 / len(X_train)\n",
    "\n",
    "# Eliminamos variables con más de un 30% de valores perdidos\n",
    "for column in X_train:\n",
    "    if mv[column] > 30.0:\n",
    "        X_train.drop(labels=[column], axis=1, inplace = True)\n",
    "        to_drop = np.append(to_drop, column)\n",
    "print(\"Tamaño train tras drop (variables con mv)\", X_train.shape)\n",
    "\n",
    "# Imputamos los valores perdidos de aquellas variables que tengan menos de un 30% de valores perdidos\n",
    "imputer = KNNImputer()\n",
    "\n",
    "X = imputer.fit_transform(X_train)\n",
    "# Eliminamos variables con varianza muy baja\n",
    "var = VarianceThreshold(threshold=(.95 * (1 - .95)))\n",
    "\n",
    "\n",
    "# Añadimos complejidad al modelo\n",
    "poly = PolynomialFeatures(2)\n",
    "X = poly.fit_transform(X)\n",
    "print(\"Tras poli\", X.shape)\n",
    "X = var.fit_transform(X)\n",
    "print(\"Tras var\", X.shape)\n",
    "# Reducimos mediante regularización lasso\n",
    "#lasso = Lasso(max_iter = 100000, alpha = 0.01)\n",
    "lasso = LassoCV(n_jobs = -1, max_iter = 50000, verbose = True, cv = 4)\n",
    "\n",
    "preprocessing = Pipeline(steps=[\n",
    "    ('imputer', imputer),\n",
    "#    ('scale',StandardScaler()),\n",
    "    ('poly', poly),\n",
    " #   ('Variance', var),\n",
    "    ('lasso', SelectFromModel(lasso))])\n",
    "\n",
    "X_train = preprocessing.fit_transform(X_train, y_train)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Grid Search...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros:\n",
      "{'alpha': 0.0001, 'learning_rate': 'adaptive', 'max_iter': 5000}\n",
      "0.014417125201410069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 240 out of 240 | elapsed:  4.5min finished\n"
     ]
    }
   ],
   "source": [
    "lreg =  SGDRegressor(tol=1e-4)\n",
    "lreg.fit(X_train, y_train)\n",
    "params_lreg =  {'alpha':[1/(10.0**i) for i in range(1,5)], 'learning_rate':['constant', 'optimal','invscaling', 'adaptive'], 'max_iter':[5000,10000,15000]}\n",
    "\n",
    "\n",
    "best_lreg = adjust_params(X_train, y_train, lreg, params_lreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499, 100)\n"
     ]
    }
   ],
   "source": [
    "# Preprocesamos el conjunto de test \n",
    "X_test = X_test.drop(labels = to_drop, axis=1)\n",
    "print(X_test.shape)\n",
    "X_test = preprocessing.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 88)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio en test: 0.0234\n"
     ]
    }
   ],
   "source": [
    "# Utilizando el mejor modelo predecimos el valor de X_test\n",
    "y_pred = best_lreg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Error cuadrático medio en test: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
